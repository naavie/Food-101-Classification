{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this project you are asked to create an ML-service to solve any kind of task.\n",
    "\n",
    "You should define the task you are going to solve. Task definition should contain input and output description, approach chosen to solve (model description), dataset for model training and runtime architecture for the resulting service.\n",
    "\n",
    "You can publish your code on private GitHub repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details for the project structure:\n",
    "\n",
    "1. Project documentation\n",
    "\n",
    "* 1.1. design document\n",
    "\n",
    "* 1.2. run instructions (env, commands)\n",
    "\n",
    "* 1.3. architecture, losses, metrics\n",
    "\n",
    "2. Data set\n",
    "\n",
    "3. Model training code.\n",
    "\n",
    "* 3.1. Jupyter Notebook\n",
    "\n",
    "* 3.2. MLFlow project\n",
    "\n",
    "4. Service deployment and usage instructions\n",
    "\n",
    "* 4.1. dockerfile or docker-compose file\n",
    "\n",
    "* 4.2. required services: databases\n",
    "\n",
    "* 4.3. client for service\n",
    "\n",
    "* 4.4. model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Project Documentation**\n",
    "    * 1.1. Design Document: Describe the problem you're solving, why you chose ResNet50, and how you're fine-tuning it.\n",
    "    * 1.2. Run Instructions: Document the environment setup (Python version, required libraries), and the commands to run your code.\n",
    "    * 1.3. Architecture, Losses, Metrics: Describe the architecture of ResNet50, the loss function you're using (e.g., CrossEntropyLoss for multi-class classification), and the metrics (e.g., accuracy).\n",
    "\n",
    "2. **Dataset**\n",
    "    * Describe the Food-101 dataset, how you selected 50 subclasses, and how you split the data into training, validation, and test sets.\n",
    "\n",
    "3. **Model Training Code**\n",
    "    * 3.1. Jupyter Notebook: Write the code for data loading, model training, and evaluation in a Jupyter notebook.\n",
    "    * 3.2. MLFlow Project: Use MLFlow to track your experiments, log metrics, and save models.\n",
    "\n",
    "4. **Service Deployment and Usage Instructions**\n",
    "    * 4.1. Dockerfile or Docker-compose file: Create a Dockerfile for your service, which includes the environment setup and the command to run your service.\n",
    "    * 4.2. Required Services: Databases: If you need to store results, describe the database you're using.\n",
    "    * 4.3. Client for Service: Provide a client script to call your service and get predictions.\n",
    "    * 4.4. Model: Include instructions on how to load the trained model for making predictions.\n",
    "\n",
    "Remember, this is a high-level plan. Each step will involve more detailed tasks. For example, for model training, you'll need to write code for data loading, data augmentation, model training, model validation, and model saving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful links:\n",
    "\n",
    "- Datasets: http://kaggle.com/\n",
    "- Finished Models: https://paperswithcode.com/\n",
    "- GPU Learning (limited, but suitable for Learning Transfer): http://colab.research.google.com/\n",
    "- Recommended Models for Learning Transfer:\n",
    "\n",
    "- text - BERT\n",
    "- images - Big Transfer\n",
    "\n",
    "Project examples:\n",
    "- Image or text classification and semantics analysis\n",
    "- Lyrics generator with musician style (RNN model)\n",
    "- Image super resolution (CNN)\n",
    "- Image inpainting or generation (GAN, vAE, DDPMs)\n",
    "- Image Style Transfer (GAN model)\n",
    "- House price prediction based on image and table information\n",
    "- Tags generation for StackOverflow questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Criteria\n",
    "\n",
    "1.5 points – data collection and model training. Points could be taken away for:\n",
    "- improper use of data\n",
    "- incorrect train/test/va split\n",
    "- little data\n",
    "- poor model quality evaluation\n",
    "- no comparison to baseline\n",
    "- no estimate of model runtime and size\n",
    "\n",
    "1.5 points – service implementation. Criteria: Justification of architecture selection based on evaluation of:\n",
    "- the service\n",
    "- possible RPS (requests per second)\n",
    "- models used\n",
    "- implementation of backend architecture\n",
    "- implementation of some interface (API or UI)\n",
    "- evaluation of service quality, operation/response time\n",
    "\n",
    "1 point – answers to additional questions on the implementation\n",
    "\n",
    "You are allowed to create any kind service, as long as there is a clear objective and solution\n",
    "\n",
    "Total: 4 points\n",
    "\n",
    "You should submit GitHub or GitLab repo that meets the requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, Docker is a great choice for building the web service. It allows you to package your application along with all its dependencies into a container, which can then be run on any system that has Docker installed. This ensures that your application will run the same way regardless of the environment.\n",
    "\n",
    "Here's a high-level overview of how you might use Docker in this project:\n",
    "\n",
    "1. **Dockerfile:** Write a Dockerfile for your application. This is a script that contains instructions for how to build the Docker image. It will specify the base image (e.g., a Python image), the application's dependencies (which can be installed with pip), and the application's entry point.\n",
    "\n",
    "2. **Build the Docker Image:** Use the `docker build` command to build the Docker image based on the Dockerfile.\n",
    "\n",
    "3. **Run the Docker Container:** Use the `docker run` command to run a container based on the Docker image. This will start the web service.\n",
    "\n",
    "4. **Docker Compose:** If your application has multiple services (e.g., a web service and a database), you can use Docker Compose to manage them. With a docker-compose.yml file, you can start all your services with a single command (`docker-compose up`).\n",
    "\n",
    "Remember to include instructions for building and running the Docker image in your project's documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the grading scale, here's how you can approach your project:\n",
    "\n",
    "1. **Data Collection and Model Training (1.5 points)**\n",
    "\n",
    "    - **Proper use of data**: Ensure that you're using the Food-101 dataset correctly. For example, don't use test data for training.\n",
    "    - **Train/Test/Validation split**: Use a standard split such as 70% for training, 15% for validation, and 15% for testing.\n",
    "    - **Data size**: The Food-101 dataset is quite large, so this shouldn't be an issue. If you're only using 50 subclasses, make sure you have enough examples for each class.\n",
    "    - **Model quality evaluation**: Use appropriate metrics such as accuracy, precision, recall, and F1 score. Also, plot confusion matrices or ROC curves if applicable.\n",
    "    - **Comparison to baseline**: You could use a simpler model (like a basic CNN) as a baseline and compare its performance with your fine-tuned ResNet50.\n",
    "    - **Estimate of model runtime and size**: Measure the time it takes to train your model and to make predictions. Also, note the size of the saved model file.\n",
    "\n",
    "2. **Service Implementation (1.5 points)**\n",
    "\n",
    "    - **Justification of architecture selection**: Explain why you chose ResNet50 and how it's suitable for your task.\n",
    "    - **The service**: Describe your service, what it does (e.g., takes an image and returns a prediction of the food class), and how it uses your trained model.\n",
    "    - **Possible RPS (requests per second)**: Estimate how many requests your service can handle per second. This will depend on the runtime of your model and the resources of your server.\n",
    "    - **Models used**: Document the use of the ResNet50 model, how it was trained, and how it's used in the service.\n",
    "    - **Implementation of backend architecture**: Describe the backend of your service, e.g., how requests are handled, how the model is loaded and used, etc.\n",
    "    - **Implementation of some interface (API or UI)**: Implement an API for your service that clients can use to send requests and receive predictions. If you're ambitious, you could also create a simple web UI.\n",
    "    - **Evaluation of service quality, operation/response time**: Measure and document the response time of your service, i.e., how long it takes to return a prediction after receiving a request."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
